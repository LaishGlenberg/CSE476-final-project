{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "393516c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Minimal setup\n",
    "# If needed (uncomment in a notebook):\n",
    "# !pip install requests python-dotenv\n",
    "\n",
    "import os, json, textwrap, re, time\n",
    "import requests\n",
    "\n",
    "API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"cse476\")\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\")  \n",
    "MODEL    = os.getenv(\"MODEL_NAME\", \"bens_model\")              \n",
    "\n",
    "def call_model_chat_completions(prompt: str,\n",
    "                                system: str = \"You are a helpful assistant. Reply with only the final answer—no explanation.\",\n",
    "                                model: str = MODEL,\n",
    "                                temperature: float = 0.3,\n",
    "                                timeout: int = 60,\n",
    "                                max_tokens: int = 128) -> dict:\n",
    "    \"\"\"\n",
    "    Calls an OpenAI-style /v1/chat/completions endpoint and returns:\n",
    "    { 'ok': bool, 'text': str or None, 'raw': dict or None, 'status': int, 'error': str or None, 'headers': dict }\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "        status = resp.status_code\n",
    "        hdrs   = dict(resp.headers)\n",
    "        if status == 200:\n",
    "            data = resp.json()\n",
    "            text = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return {\"ok\": True, \"text\": text, \"raw\": data, \"status\": status, \"error\": None, \"headers\": hdrs}\n",
    "        else:\n",
    "            # try best-effort to surface error text\n",
    "            err_text = None\n",
    "            try:\n",
    "                err_text = resp.json()\n",
    "            except Exception:\n",
    "                err_text = resp.text\n",
    "            return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": status, \"error\": str(err_text), \"headers\": hdrs}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": -1, \"error\": str(e), \"headers\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f36f76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b46dc9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Direct call example\n",
    "def direct_call(prompt=\"What is 17 + 28? Answer with just the number.\", temperature=0.2, max_tokens=128):\n",
    "    demo_prompt = prompt\n",
    "    result = call_model_chat_completions(demo_prompt, temperature=temperature, max_tokens=max_tokens)\n",
    "    print(\"OK:\", result[\"ok\"], \"HTTP:\", result[\"status\"])\n",
    "    print(\"MODEL SAYS:\", (result[\"text\"] or \"\").strip())\n",
    "\n",
    "    # Optional: Inspect rate-limit headers if your provider exposes them\n",
    "    for k in [\"x-ratelimit-remaining-requests\", \"x-ratelimit-limit-requests\", \"x-request-id\"]:\n",
    "        if k in result[\"headers\"]:\n",
    "            print(f\"{k}: {result['headers'][k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a3b0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define three tests: input + expected\n",
    "my_tests = [\n",
    "    {\n",
    "        \"id\": \"math_inequality\",\n",
    "        \"type\": \"numeric\",  # grader will prefer numeric extraction\n",
    "        \"prompt\": \"Solve for the smallest integer n such that 3n + 5 > 26. Answer with just the integer.\",\n",
    "        \"expected\": \"8\",    # Because 3n > 21 => n > 7, smallest integer is 8\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"commonsense_ice\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"You place an ice cube in a glass of water and mark the water level. \"\n",
    "            \"After the ice melts, does the water level rise, fall, or stay the same? \"\n",
    "            \"Answer with exactly one of: 'rise', 'fall', 'stay the same'.\"\n",
    "        ),\n",
    "        \"expected\": \"stay the same\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"logic_race\",\n",
    "        \"type\": \"text\",\n",
    "        \"prompt\": (\n",
    "            \"In a race, you pass the person in second place. What position are you now in? \"\n",
    "            \"Answer with a single word like 'first', 'second', 'third'.\"\n",
    "        ),\n",
    "        \"expected\": \"second\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9af2b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "POSSIBLE_TYPES = ['math', 'common_sense', 'planning', 'coding', 'future_prediction']\n",
    "\n",
    "all_tests = json.load(open(\"parsed_dev_data.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "formatted_tests = []\n",
    "for i, t in enumerate(all_tests, start=1):\n",
    "    \n",
    "    formatted_tests.append({\n",
    "        \"id\": t['id'], # domain_domainIndex_domainTestIndex_testIndex\n",
    "        \"type\": t['domain'],\n",
    "        \"prompt\": t['input'],\n",
    "        \"expected\": t['output'],\n",
    "        \"char_count\": t['input_char_count']\n",
    "    })\n",
    "    \n",
    "all_tests = formatted_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9fe04856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test(test):\n",
    "    print(json.dumps(test, indent=2, ensure_ascii=False))\n",
    "\n",
    "#pass test_type as a list of types\n",
    "def get_test_type(test_type, start=0, end=None, lower=0, upper=float('inf')):\n",
    "    tests = [t for t in all_tests if t['type'] in test_type and lower <= t['char_count'] <= upper]\n",
    "    return tests[start:end]\n",
    "\n",
    "def get_random_tests(n=5, lower=0, upper=float('inf'), test_type=POSSIBLE_TYPES):\n",
    "    filtered_tests = get_test_type(test_type=test_type, lower=lower, upper=upper) #[t for t in all_tests if lower <= t['char_count'] <= upper]\n",
    "    sample_size = min(n, len(filtered_tests)) #prevent error\n",
    "    return random.sample(filtered_tests, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f75a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'char_count': 84,\n",
      "  'expected': '-125',\n",
      "  'id': 'math_3_272_872',\n",
      "  'prompt': 'Find the constant term in the expansion of '\n",
      "            '$$\\\\left(10x^3-\\\\frac{1}{2x^2}\\\\right)^{5}$$',\n",
      "  'type': 'math'},\n",
      " {'char_count': 275,\n",
      "  'expected': 'Jerry will spend 8 games x 2 hours per game = <<8*2=16>>16 '\n",
      "              'hours watching one daughter play her games.\\n'\n",
      "              'He will spend 16 x 2 = <<16*2=32>>32 hours watching both '\n",
      "              'daughters play their games.\\n'\n",
      "              'He will spend 8 games x 4 hours of practice = <<8*4=32>>32 '\n",
      "              'hours watching one daughter practice.\\n'\n",
      "              'He will spend 32 x 2 = <<32*2=64>>64 hours watching both '\n",
      "              'daughters practice.\\n'\n",
      "              'He will spend a total of 32 hours watching games + 64 hours '\n",
      "              'watching practice = <<32+64=96>>96 hours.\\n'\n",
      "              '#### 96',\n",
      "  'id': 'math_3_110_710',\n",
      "  'prompt': 'Jerry’s two daughters play softball on different teams. They each '\n",
      "            'have 8 games this season. Each team practices 4 hours for every '\n",
      "            'game they play. If each game lasts for 2 hours, how many hours '\n",
      "            'will Jerry spend at the field watching his daughters play and '\n",
      "            'practice altogether?',\n",
      "  'type': 'math'},\n",
      " {'char_count': 290,\n",
      "  'expected': '12',\n",
      "  'id': 'math_3_92_692',\n",
      "  'prompt': 'A regular octagon has the same perimeter as the regular hexagon '\n",
      "            'shown here with side length 16 cm.  How long is each side of the '\n",
      "            'octagon? [asy]size(80); pair A = dir(120); pair B=dir(60); pair '\n",
      "            'M=(A+B)/2; '\n",
      "            'draw(dir(360)--B--A--dir(180)--dir(240)--dir(300)--cycle); '\n",
      "            'label(\"16 cm\", M, N);[/asy]',\n",
      "  'type': 'math'},\n",
      " {'char_count': 233,\n",
      "  'expected': 'Arnel shared 5 x 8 = <<5*8=40>>40 pencils with his friends.\\n'\n",
      "              'So, he had 10 + 40 = <<10+40=50>>50 pencils in all.\\n'\n",
      "              'Therefore, each box had 50/10 = <<50/10=5>>5 pencils inside.\\n'\n",
      "              '#### 5',\n",
      "  'id': 'math_3_143_743',\n",
      "  'prompt': 'Arnel had ten boxes of pencils with the same number of pencils in '\n",
      "            'each box.  He kept ten pencils and shared the remaining pencils '\n",
      "            'equally with his five friends. If his friends got eight pencils '\n",
      "            'each, how many pencils are in each box?',\n",
      "  'type': 'math'},\n",
      " {'char_count': 248,\n",
      "  'expected': 'The number of books borrowed on Friday is higher by 40 * 40/100 '\n",
      "              '= <<40*40/100=16>>16 books.\\n'\n",
      "              'There are 5 days from Monday to Friday inclusive, so Krystian '\n",
      "              'borrows an average of 5 * 40 = <<5*40=200>>200 books during '\n",
      "              'that time.\\n'\n",
      "              \"With Friday's increase in borrowings, during one week Krystian \"\n",
      "              'borrows 200 + 16 = <<200+16=216>>216 books.\\n'\n",
      "              '#### 216',\n",
      "  'id': 'math_3_137_737',\n",
      "  'prompt': 'Krystian works in the library. He borrows an average of 40 books '\n",
      "            'every day. Every Friday, his number of borrowed books is about '\n",
      "            '40% higher than the daily average. How many books does he borrow '\n",
      "            'in a week if the library is open from Monday to Friday?',\n",
      "  'type': 'math'}]\n"
     ]
    }
   ],
   "source": [
    "tests = get_random_tests(upper=400, test_type=['math']) #get_test_type('math', end=10, lower=0, upper=500)\n",
    "pprint(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b72b0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple hello world call to kick off the commits\n",
    "#direct_call(prompt=\"how do I find the derivative of y=x^2 using python?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54e39fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    messages = [\"<Start of message history>\"]\n",
    "    count = 0\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "        response = call_model_chat_completions(prompt=f\"Old messages{messages}, CURRENT USER INPUT:{user_input} <--- ANSWER THIS QUESTION\", temperature=0.7)\n",
    "        count += 1\n",
    "        messages.append(f\"MESSAGE_{count}_[previous user input: {user_input}, previous system response: {response['text']}]\")\n",
    "        if response[\"ok\"]:\n",
    "            print(\"Model:\", response[\"text\"].strip())\n",
    "        else:\n",
    "            print(\"Error:\", response[\"error\"])\n",
    "        print(messages)\n",
    "#interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb6d8dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def execute_tests():\\n    rows = []\\n    for t in tests:\\n        r = call_model_chat_completions(\\n            prompt,\\n            system=system,\\n            model=model,\\n            temperature=0.3,\\n            max_tokens=128\\n        ) '"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def execute_tests():\n",
    "    rows = []\n",
    "    for t in tests:\n",
    "        r = call_model_chat_completions(\n",
    "            prompt,\n",
    "            system=system,\n",
    "            model=model,\n",
    "            temperature=0.3,\n",
    "            max_tokens=128\n",
    "        ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e38f632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate(question, prediction, expected_answer, model=MODEL):\n",
    "    \"\"\"\n",
    "    Use the model itself as a strict grader.\n",
    "    Returns True if the model says the prediction matches the expected answer; else False.\n",
    "    Falls back to a simple normalized string compare if the model's reply is malformed.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    system = \"You are a strict grader. Reply with exactly True or False. No punctuation. No explanation.\"\n",
    "    prompt = f\"\"\"You are grading a question-answer pair.\n",
    "\n",
    "Return exactly True if the PREDICTION would be accepted as correct for the EXPECTED_ANSWER.\n",
    "Otherwise, return False.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "PREDICTION:\n",
    "{prediction}\n",
    "\n",
    "EXPECTED_ANSWER:\n",
    "{expected_answer}\n",
    "\n",
    "Answer with exactly: True or False\n",
    "\"\"\"\n",
    "\n",
    "    r = call_model_chat_completions(\n",
    "        prompt,\n",
    "        system=system,\n",
    "        model=model,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    reply = (r.get(\"text\") or \"\").strip().lower()\n",
    "    if reply.startswith(\"true\"):\n",
    "        return True\n",
    "    if reply.startswith(\"false\"):\n",
    "        return False\n",
    "\n",
    "    # No Fallback yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7cdafb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_evaluate_tests(tests, model=MODEL, grader_model=None, sleep_sec=0.2, verbose=True):\n",
    "    \"\"\"\n",
    "    Run the tests by querying the model for each prompt, then use LLM-as-a-judge\n",
    "    (self_evaluate) to determine correctness.\n",
    "\n",
    "    Args:\n",
    "        tests: list of dicts with keys: id, prompt, expected (and optionally type)\n",
    "        model: model used to generate predictions\n",
    "        grader_model: model used to judge correctness (defaults to `model` if None)\n",
    "        sleep_sec: small delay between calls to be polite to the API\n",
    "        verbose: if True, print a summary line per test\n",
    "\n",
    "    Returns:\n",
    "        rows: list of dicts with fields:\n",
    "              id, expected, got, correct, status, error\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    judge_model = grader_model or model\n",
    "    rows = []\n",
    "    count = 0\n",
    "    for t in tests:\n",
    "        count += 1\n",
    "        # 1) Get model prediction\n",
    "        #print('prompt:', t['prompt'])\n",
    "        print_test(t)\n",
    "        r = call_model_chat_completions(\n",
    "            f\"{t['prompt']}\",\n",
    "            system=\"Give a short answer to each prompt, don't explain.\",\n",
    "            model=model,\n",
    "            temperature=0.3,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        got = (r.get(\"text\") or \"\").strip()\n",
    "        display(Markdown(f\"OUTPUT: \\n{got}\"))\n",
    "        # 2) LLM-as-a-judge: strict True/False\n",
    "        \"\"\" is_correct = self_evaluate(\n",
    "            question=t[\"prompt\"],\n",
    "            prediction=got,\n",
    "            expected_answer=t[\"expected\"],\n",
    "            model=judge_model,\n",
    "        )\n",
    "\n",
    "        row = {\n",
    "            \"id\": t.get(\"id\", \"<unnamed>\"),\n",
    "            \"expected\": t[\"expected\"],\n",
    "            \"got\": got,\n",
    "            \"correct\": bool(is_correct),\n",
    "            \"status\": r.get(\"status\"),\n",
    "            \"error\": r.get(\"error\"),\n",
    "        }\n",
    "        \n",
    "        rows.append(row)\n",
    "        print(json.dumps(row, indent=2, ensure_ascii=False))\n",
    "        if verbose:\n",
    "            mark = \"✅\" if is_correct else \"❌\"\n",
    "            print(f\"{mark} {row['id']}: expected={row['expected']!r}, got={row['got']!r} (HTTP {row['status']})\")\n",
    "            if row[\"error\"]:\n",
    "                print(\"   error:\", row[\"error\"]) \"\"\"\n",
    "\n",
    "        if sleep_sec:\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "    return rows\n",
    "\n",
    "# Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7eacd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_185_785\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"The set of points $(x,y,z)$ that satisfy\\n\\\\[2x = 3y = -z\\\\]is a line.\\n\\nThe set of points $(x,y,z)$ that satisfy\\n\\\\[6x = -y = -4z\\\\]is another line.\\n\\nFind the angle between these lines, in degrees.\",\n",
      "  \"expected\": \"90^\\\\circ\",\n",
      "  \"char_count\": 192\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "The angle between the lines is $ \\cos^{-1}\\left(\\frac{1}{\\sqrt{3}}\\right) $, which is approximately $ 54.7^\\circ $."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_158_758\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Let $a_{0} = 2$ , $a_{1} = 5$ , and $a_{2} = 8$ , and for $n > 2$ define $a_{n}$ recursively to be the remainder when $4(a_{n-1} + a_{n-2} + a_{n-3})$ is divided by $11$ . Find $a_{2018} \\\\cdot a_{2020} \\\\cdot a_{2022}$ .\",\n",
      "  \"expected\": \"112\",\n",
      "  \"char_count\": 219\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "11"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_127_727\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Two squares of a $7\\\\times 7$ checkerboard are painted yellow, and the rest are painted green. Two color schemes are equivalent if one can be obtained from the other by applying a rotation in the plane board. How many inequivalent color schemes are possible?\",\n",
      "  \"expected\": \"300\",\n",
      "  \"char_count\": 257\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "13"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_131_731\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Paityn has 20 red hats and 24 blue hats. Her friend Zola has 4/5 times as many red hats as she has and twice the number of blue hats. If they combine all the hats together and share them equally between themselves, calculate the number of hats each gets.\",\n",
      "  \"expected\": \"Paityn has a total of 20 hats + 24 hats = <<20+24=44>>44 hats.\\nThe number of red hats that Zola has is 4/5 * 20 hats = <<4/5*20=16>>16 hats\\nZola also has 2 * 24 hats = <<2*24=48>>48 blue hats.\\nZola has a total of 48 hats + 16 hats = <<48+16=64>>64 hats.\\nWhen they combine their hats, they have 64 hats + 44 hats = <<64+44=108>>108 hats\\nIf they share the hats equally, each get 108 hats / 2 people = <<108/2=54>>54 hats/person\\n#### 54\",\n",
      "  \"char_count\": 254\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "Paityn has 20 red hats and 24 blue hats.  \n",
       "Zola has $ \\frac{4}{5} \\times 20 = 16 $ red hats and $ 2 \\times 24 = 48 $ blue hats.  \n",
       "Total hats = $ (20 + 24) + (16 + 48) = 44 + 64 = 108 $.  \n",
       "Each gets $ \\frac{108}{2} = 54 $ hats.  \n",
       "\n",
       "**Answer: 54**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_94_694\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Point $P_{}$ is located inside triangle $ABC$ so that angles $PAB, PBC,$ and $PCA$ are all congruent.  The sides of the triangle have lengths $AB=13, BC=14,$ and $CA=15,$ and the tangent of angle $PAB$ is $m/n,$ where $m_{}$ and $n_{}$ are relatively prime positive integers.  Find $m+n.$\",\n",
      "  \"expected\": \"463\",\n",
      "  \"char_count\": 288\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "To solve this problem, we recognize that point $ P $ inside triangle $ ABC $ such that $ \\angle PAB = \\angle PBC = \\angle PCA $ is known as the **equal angle point** or **isogonal conjugate** of the incenter. This special point is also known as the **Nagel point** or **equal angle point**, and it has equal angles with the sides of the triangle.\n",
       "\n",
       "Given triangle $ ABC $ with sides $ AB = 13 $, $ BC = 14 $, and $ CA = 15 $, we are to find the tangent of angle $ PAB $, which is the same as the tangent of the equal angles formed by point $ P $ with the triangle.\n",
       "\n",
       "This is a known geometric configuration, and the tangent of the equal angle can be found using the formula:\n",
       "\n",
       "$$\n",
       "\\tan(\\angle PAB) = \\frac{r}{R - r}\n",
       "$$\n",
       "\n",
       "where $ r $ is the inradius and $ R $ is the circumradius of triangle $ ABC $.\n",
       "\n",
       "### Step 1: Compute the area of triangle $ ABC $\n",
       "\n",
       "Using Heron's formula:\n",
       "\n",
       "$$\n",
       "s = \\frac{13 + 14 + 15}{2} = 21\n",
       "$$\n",
       "$$\n",
       "\\text{Area} = \\sqrt{s(s - a)(s - b)(s - c)} = \\sqrt{21 \\cdot 8 \\cdot 7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_162_762\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\",\n",
      "  \"expected\": \"He eats 32 from the largest pizzas because 2 x 16 = <<2*16=32>>32\\nHe eats 16 from the small pizza because 2 x 8 = <<2*8=16>>16\\nHe eats 48 pieces because 32 + 16 = <<32+16=48>>48\\n#### 48\",\n",
      "  \"char_count\": 217\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "24 slices"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_181_781\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Sam memorized six more digits of pi than Carlos memorized. Mina memorized six times as many digits of pi as Carlos memorized. If Mina memorized 24 digits of pi, how many digits did Sam memorize?\",\n",
      "  \"expected\": \"Carlos memorized 24/6=<<24/6=4>>4 digits of pi.\\nSam memorized 4+6=10 digits of pi.\\n#### 10\",\n",
      "  \"char_count\": 194\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "12"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_145_745\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\",\n",
      "  \"expected\": \"She works 8 hours a day for $18 per hour so she makes 8*18 = $<<8*18=144.00>>144.00 per 8-hour shift\\nShe works 10 hours a day and anything over 8 hours is eligible for overtime, so she gets 10-8 = <<10-8=2>>2 hours of overtime\\nOvertime is calculated as time and a half so and she makes $18/hour so her overtime pay is 18*.5 = $<<18*.5=9.00>>9.00\\nHer overtime pay is 18+9 = $<<18+9=27.00>>27.00\\nHer base pay is $144.00 per 8-hour shift and she works 5 days and makes 5 * $144 = $<<144*5=720.00>>720.00\\nHer overtime pay is $27.00 per hour and she works 2 hours of overtime per day and makes 27*2 = $<<27*2=54.00>>54.00 in overtime pay\\n2 hours of overtime pay for 5 days means she makes 54*5 = $270.00\\nIn 5 days her base pay is $720.00 and she makes $270.00 in overtime pay so she makes $720 + $270 = $<<720+270=990.00>>990.00\\n#### 990\",\n",
      "  \"char_count\": 232\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "$270.00"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_108_708\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Leo's assignment was divided into three parts. He finished the first part of his assignment in 25 minutes. It took him twice as long to finish the second part. If he was able to finish his assignment in 2 hours, how many minutes did Leo finish the third part of the assignment?\",\n",
      "  \"expected\": \"It took Leo 25 x 2 = <<25*2=50>>50 minutes to finish the second part of the assignment.\\nLeo finished the first and second parts of the assignment in 25 + 50 = <<25+50=75>>75 minutes.\\nHe finished the entire assignment in 60 x 2 = <<60*2=120>>120 minutes.\\nTherefore, it took Leo 120 - 75 = <<120-75=45>>45 minutes to finish the third part of the assignment.\\n#### 45\",\n",
      "  \"char_count\": 277\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "First part: 25 minutes  \n",
       "Second part: 2 × 25 = 50 minutes  \n",
       "Total time: 2 hours = 120 minutes  \n",
       "Third part: 120 - 25 - 50 = 45 minutes  \n",
       "\n",
       "45"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"math_3_283_883\",\n",
      "  \"type\": \"math\",\n",
      "  \"prompt\": \"Half the value of $3x-9$ is $x+37$. What is the value of $x$?\",\n",
      "  \"expected\": \"83\",\n",
      "  \"char_count\": 61\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OUTPUT: \n",
       "$ x = 23 $"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prompts = get_random_tests(n=10, upper=300, test_type=[\"math\"])#get_test_type([\"math\"],end=10, upper=300) get_random_tests(n=3, upper=300)\n",
    "results_llm_judge = self_evaluate_tests(test_prompts, verbose=True, model=MODEL, grader_model=MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
